
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction &#8212; Introduction to Data Science with Python</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="An Introductory Example" href="python_by_example.html" />
    <link rel="prev" title="Setting up Your Python Environment" href="getting_started.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/qe-logo-large.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Data Science with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Dieses Buch durchsuchen ..." aria-label="Dieses Buch durchsuchen ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-crispdm.html">
   Data Science Lifecycle
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Regression
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="03-classification.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="04-reference.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navigation umschalten" aria-controls="site-navigation"
                title="Navigation umschalten" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Laden Sie diese Seite herunter"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/02-regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Quelldatei herunterladen" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="In PDF drucken"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Vollbildmodus"
        title="Vollbildmodus"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Inhalt
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Introduction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#business-understanding">
   Business understanding
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-understanding">
   Data understanding
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imort-data">
     Imort Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clean-data">
     Clean data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#format-data">
     Format data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convert-to-numeric">
   convert to numeric
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convert-all-remaining-character-variables-to-factors">
   convert all remaining character variables to factors
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-data">
     Missing data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-new-variables">
     Create new variables
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-overview">
     Data overview
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-splitting">
     Data splitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fix-the-random-numbers-by-setting-the-seed">
   Fix the random numbers by setting the seed
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#this-enables-the-analysis-to-be-reproducible">
   This enables the analysis to be reproducible
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#put-3-4-of-the-data-into-the-training-set">
   Put 3/4 of the data into the training set
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-dataframes-for-the-two-sets">
   Create dataframes for the two sets:
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-exploration">
     Data exploration
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-data-copy">
       Create data copy
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#geographical-overview">
       Geographical overview
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#boxplots">
       Boxplots
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#correlations">
       Correlations
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#visual-inspections">
       Visual inspections
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   Data preparation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Data preparation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-prepropecessing-recipe">
     Data prepropecessing recipe
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#validation-set">
     Validation set
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-building">
   Model building
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specify-models">
     Specify models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lasso-regression">
       Lasso regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#natural-spline">
       Natural spline
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#random-forest">
       Random forest
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#boosted-tree-xgboost">
       Boosted tree (XGBoost)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#k-nearest-neighbor">
       K-nearest neighbor
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#create-workflows">
     Create workflows
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lasso">
       Lasso
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Natural spline
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Random forest
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboost">
       XGBoost
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       K-nearest neighbor
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-models">
     Evaluate models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Lasso regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Natural spline
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       Random forest
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       XGBoost
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       K-nearest neighbor
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#compare-models">
       Compare models
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#last-fit-and-evaluation-on-test-set">
     Last fit and evaluation on test set
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="introduction">
<span id="file-types-notebooks"></span><h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>In this chapter, we’ll build the following models:</p>
<ul class="simple">
<li><p>lasso,</p></li>
<li><p>natural spline,</p></li>
<li><p>random forest,</p></li>
<li><p>XGBoost (extreme gradient boosted trees)</p></li>
<li><p>K-nearest neighbor</p></li>
</ul>
<p><em>Lasso</em> performs a so called L1 regularization (a process of introducing additional information in order to prevent overfitting). In particular, it adds a penalty equivalent to the absolute value of the magnitude of coefficients. See &#64;James2000 for more details about lasso regression.</p>
<p>A <em>natural spline</em> is an advancement of a piecewise polynomial regression spline which involves fitting separate low-degree polynomials over different regions of our predictor space X. In particular, a natural spline is a regression spline with additional boundary constraints: the function is required to be linear at the boundary (in the region where X is smaller than the smallest knot, or larger than the largest knot). This additional constraint means that natural splines generally produce more stable estimates at the boundaries. See &#64;James2000 for more details about piecewise polynomial regression splines and natural splines.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="business-understanding">
<h1>Business understanding<a class="headerlink" href="#business-understanding" title="Permalink to this headline">¶</a></h1>
<div class="highlight-note notranslate"><div class="highlight"><pre><span></span>In business understanding, you:

- Define your (business) goal
- Frame the problem (regression, classification,...)
- Choose a performance measure
- Show the data processing components
</pre></div>
</div>
<p>First of all, we take a look at the big picture and define the objective of our data science project in business terms.</p>
<p>In our example, the goal is to build a model of housing prices in California. In particular, the model should learn from California census data and be able to predict the median house price in any district (population of 600 to 3000 people), given some predictor variables. Hence, we face a <strong>supervised learning</strong> situation and should use a <strong>regression model</strong> to predict the numerical outcomes. Furthermore, we use the <strong>root mean square error (RMSE)</strong> as a performance measure for our regression problem.</p>
<p>Let’s assume that the model’s output (a prediction of a district’s median housing price) will be fed to another analytics system, along with other data. This downstream system will determine whether it is worth investing in a given area or not. The <strong>data processing components</strong> (also called data pipeline) are shown in &#64;ref(fig:datapipeline) (you can use <a class="reference external" href="https://docs.google.com/presentation/d/1vjm5YdmOH5LrubFhHf1vlqW2O9Z2UqdWA8biN3e8K5U/edit#slide=id.g19b41f69d7_2_265">Google’s architectural templates</a> to draw the data pipeline).</p>
<p>knitr::include_graphics(“css/data-pipeline.png”)</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="data-understanding">
<h1>Data understanding<a class="headerlink" href="#data-understanding" title="Permalink to this headline">¶</a></h1>
<div class="highlight-note notranslate"><div class="highlight"><pre><span></span>In data understanding, you:

- Import data 
- Clean data
- Format data properly
- Create new variables
- Get an overview about the complete data
- Split data into training and test set using stratified sampling
- Discover and visualize the data to gain insights 
</pre></div>
</div>
<div class="section" id="imort-data">
<h2>Imort Data<a class="headerlink" href="#imort-data" title="Permalink to this headline">¶</a></h2>
<p>First of all, let’s import the data:</p>
<p>library(tidyverse)</p>
<p>LINK &lt;- “<a class="reference external" href="https://raw.githubusercontent.com/kirenz/datasets/master/housing_unclean.csv">https://raw.githubusercontent.com/kirenz/datasets/master/housing_unclean.csv</a>”
housing_df &lt;- read_csv(LINK)</p>
</div>
<div class="section" id="clean-data">
<h2>Clean data<a class="headerlink" href="#clean-data" title="Permalink to this headline">¶</a></h2>
<p>To get a first impression of the data we take a look at the top 4 rows:</p>
<p>library(gt)</p>
<p>housing_df %&gt;%
slice_head(n = 4) %&gt;%
gt() # print output using gt</p>
<p>Notice the values in the first row of the variables <code class="docutils literal notranslate"><span class="pre">housing_median_age</span></code> and <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>. We need to remove the strings “years” and “$” with the function <code class="docutils literal notranslate"><span class="pre">str_remove_all</span></code> from the <code class="docutils literal notranslate"><span class="pre">stringr</span></code> package. Since there could be multiple wrong entries of the same type, we apply our corrections to all of the rows of the corresponding variable:</p>
<p>library(stringr)</p>
<p>housing_df &lt;-
housing_df %&gt;%
mutate(
housing_median_age = str_remove_all(housing_median_age, “[years]”),
median_house_value = str_remove_all(median_house_value, “[$]”)
)</p>
<p>We don’t cover the phase of data cleaning in detail in this tutorial. However, in a real data science project data cleaning is usually a very time consuming process.</p>
</div>
<div class="section" id="format-data">
<h2>Format data<a class="headerlink" href="#format-data" title="Permalink to this headline">¶</a></h2>
<p>Next, we take a look at the data structure and check wether all data formats are correct:</p>
<ul class="simple">
<li><p>Numeric variables should be formatted as integers (<code class="docutils literal notranslate"><span class="pre">int</span></code>) or double precision floating point numbers (<code class="docutils literal notranslate"><span class="pre">dbl</span></code>).</p></li>
<li><p>Categorical (nominal and ordinal) variables should usually be formatted as factors (<code class="docutils literal notranslate"><span class="pre">fct</span></code>) and not characters (<code class="docutils literal notranslate"><span class="pre">chr</span></code>). Especially, if they don’t have many levels.</p></li>
</ul>
<p>glimpse(housing_df)</p>
<p>The package <code class="docutils literal notranslate"><span class="pre">visdat</span></code> helps us to explore the data class structure visually:</p>
<p>library(visdat)</p>
<p>vis_dat(housing_df)</p>
<p>We can observe that the numeric variables <code class="docutils literal notranslate"><span class="pre">housing_media_age</span></code> and <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code> are declared as characters (<code class="docutils literal notranslate"><span class="pre">chr</span></code>) instead of numeric. We choose to format the variables as <code class="docutils literal notranslate"><span class="pre">dbl</span></code>, since the values could be floating-point numbers.</p>
<p>Furthermore, the categorical variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> is formatted as character instead of factor. Let’s take a look at the levels of the variable:</p>
<p>housing_df %&gt;%
count(ocean_proximity,
sort = TRUE)</p>
<p>The variable has only 5 levels and therefore should be formatted as a factor.</p>
<p>Note that it is usually a good idea to first take care of the numerical variables. Afterwards, we can easily convert all remaining character variables to factors using the function <code class="docutils literal notranslate"><span class="pre">across</span></code> from the dplyr package (which is part of the tidyverse).</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="convert-to-numeric">
<h1>convert to numeric<a class="headerlink" href="#convert-to-numeric" title="Permalink to this headline">¶</a></h1>
<p>housing_df &lt;-
housing_df %&gt;%
mutate(
housing_median_age = as.numeric(housing_median_age),
median_house_value = as.numeric(median_house_value)
)</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="convert-all-remaining-character-variables-to-factors">
<h1>convert all remaining character variables to factors<a class="headerlink" href="#convert-all-remaining-character-variables-to-factors" title="Permalink to this headline">¶</a></h1>
<p>housing_df &lt;-
housing_df %&gt;%
mutate(across(where(is.character), as.factor))</p>
<div class="section" id="missing-data">
<h2>Missing data<a class="headerlink" href="#missing-data" title="Permalink to this headline">¶</a></h2>
<p>Now let’s turn our attention to missing data. Missing data can be viewed with the function <code class="docutils literal notranslate"><span class="pre">vis_miss</span></code> from the package <code class="docutils literal notranslate"><span class="pre">visdat</span></code>. We arrange the data by columns with most missingness:</p>
<p>vis_miss(housing_df, sort_miss = TRUE)</p>
<p>Here an alternative method to obtain missing data:</p>
<p><a class="reference external" href="http://is.na">is.na</a>(housing_df) %&gt;% colSums()</p>
<p>We have a missing rate of 0.1% (207 cases) in our variable <code class="docutils literal notranslate"><span class="pre">total_bedroms</span></code>. This can cause problems for some algorithms. We will take care of this issue during our data preparation phase.</p>
</div>
<div class="section" id="create-new-variables">
<h2>Create new variables<a class="headerlink" href="#create-new-variables" title="Permalink to this headline">¶</a></h2>
<p>One very important thing you may want to do at the beginning of your data science project is to create new variable combinations. For example:</p>
<ul class="simple">
<li><p>the <em>total number of rooms</em> in a district is not very useful if you don’t know how many households there are. What you really want is the <em>number of rooms per household</em>.</p></li>
<li><p>Similarly, the total number of bedrooms by itself is not very useful: you probably want to compare it to the number of rooms.</p></li>
<li><p>And the <em>population per household</em> also seems like an interesting attribute combination to look at.</p></li>
</ul>
<p>Let’s create these new attributes:</p>
<p>housing_df &lt;-
housing_df %&gt;%
mutate(rooms_per_household = total_rooms/households,
bedrooms_per_room = total_bedrooms/total_rooms,
population_per_household = population/households)</p>
</div>
<div class="section" id="data-overview">
<h2>Data overview<a class="headerlink" href="#data-overview" title="Permalink to this headline">¶</a></h2>
<p>After we took care of our data problems, we can obtain a data summary of all numerical and categorical attributes using a function from the package <code class="docutils literal notranslate"><span class="pre">skimr</span></code>:</p>
<p>skim(housing_df)</p>
<p>We have <code class="docutils literal notranslate"><span class="pre">r</span> <span class="pre">nrow(housing_df)</span></code> observations and <code class="docutils literal notranslate"><span class="pre">r</span> <span class="pre">ncol(housing_df)</span></code> columns in our data.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">sd</span></code> column shows the standard deviation, which measures how dispersed the values are.</p></li>
<li><p>The p0, p25, p50, p75 and p100 columns show the corresponding percentiles: a percentile indicates the value below which a given percentage of observations in a group of observations fall. For example, 25% of the districts have a <code class="docutils literal notranslate"><span class="pre">housing_median_age</span></code> lower than 18, while 50% are lower than 29 and 75% are lower than 37. These are often called the 25th percentile (or first quartile), the median, and the 75th percentile.</p></li>
<li><p>Further note that the <strong>median income</strong> attribute does not look like it is expressed in US dollars (USD). Actually the data has been scaled and capped at 15 (actually, 15.0001) for higher median incomes, and at 0.5 (actually, 0.4999) for lower median incomes. The numbers represent roughly tens of thousands of dollars (e.g., 3 actually means about $30,000).</p></li>
</ul>
<p>Another quick way to get an overview of the type of data you are dealing with is to plot a histogram for each numerical attribute. A histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis). You can either plot this one attribute at a time, or you can use <code class="docutils literal notranslate"><span class="pre">ggscatmat</span></code> from the package <code class="docutils literal notranslate"><span class="pre">GGally</span></code> on the whole dataset (as shown in the following code example), and it will plot a histogram for each numerical attribute as well as  correlation coefficients (Pearson is the default). We just select the most promising variabels for our plot:</p>
<p>library(GGally)</p>
<p>housing_df %&gt;%
select(
median_house_value, housing_median_age,
median_income, bedrooms_per_room, rooms_per_household,
population_per_household) %&gt;%
ggscatmat(alpha = 0.2)</p>
<p>Another option is to use <code class="docutils literal notranslate"><span class="pre">ggpairs</span></code>, where we even can integrate our categorical variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> in the output:</p>
<p>library(GGally)</p>
<p>housing_df %&gt;%
select(
median_house_value, housing_median_age,
median_income, bedrooms_per_room, rooms_per_household,
population_per_household,
ocean_proximity) %&gt;%
ggpairs()</p>
<p>There are a few things you might notice in these histograms:</p>
<ul class="simple">
<li><p>The variables <em>median income</em>, <em>housing median age</em> and the <em>median house value</em> were capped. The latter may be a serious problem since it is our target attribute (your y label). Our Machine Learning algorithms may learn that prices never go beyond that limit. This will be a serious problem if we need predictions beyond 500,000. We take care of this issue in our data preparation phase and only use districts below 500,000.</p></li>
<li><p>Note that our attributes have very different scales. We will take care of this issue later in data preparation, when we use feature scaling (data normalization).</p></li>
<li><p>Finally, many histograms are tail-heavy: they extend much farther to the right of the median than to the left. This may make it a bit harder for some Machine Learning algorithms to detect patterns. We will transform these attributes later on to have more bell-shaped distributions. For our right-skewed data (i.e., tail is on the right, also called positive skew), common transformations include square root and log (we will use the log).</p></li>
</ul>
</div>
<div class="section" id="data-splitting">
<h2>Data splitting<a class="headerlink" href="#data-splitting" title="Permalink to this headline">¶</a></h2>
<p>Before we get started with our in-depth data exploration, let’s split our single dataset into two: a training set and a testing set. The training data will be used to fit models, and the testing set will be used to measure model performance. We perform data exploration only on the training data.</p>
<p>A <strong>training dataset</strong> is a dataset of examples used during the learning process and is used to fit the models. A <strong>test dataset</strong> is a dataset that is independent of the training dataset and is used to evaluate the performance of the final model. If a model fit to the training dataset also fits the test dataset well, minimal <em>overfitting</em> has taken place. A better fitting of the training dataset as opposed to the test dataset usually points to overfitting.</p>
<p>In our data split, we want to ensure that the training and test set is representative of the various categories of median house values in the whole dataset. Take a look at &#64;ref(fig:hist-med-value)</p>
<p>housing_df %&gt;%
ggplot(aes(median_house_value)) +
geom_histogram(bins = 4)</p>
<p>In general, we would like to have instances for each <em>stratum</em>, or else the estimate of a stratum’s importance may be biased. A <em>stratum</em> (plural strata) refers to a subset (part) of the whole data from which is being sampled. You should not have too many strata, and each stratum should be large enough. We use 4 strata in our example.</p>
<p>To actually split the data, we can use the <code class="docutils literal notranslate"><span class="pre">rsample</span></code> package (included in <code class="docutils literal notranslate"><span class="pre">tidymodels</span></code>) to create an object that contains the information on how to split the data (which we call <code class="docutils literal notranslate"><span class="pre">data_split</span></code>), and then two more <code class="docutils literal notranslate"><span class="pre">rsample</span></code> functions to create data frames for the training and testing sets:</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="fix-the-random-numbers-by-setting-the-seed">
<h1>Fix the random numbers by setting the seed<a class="headerlink" href="#fix-the-random-numbers-by-setting-the-seed" title="Permalink to this headline">¶</a></h1>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="this-enables-the-analysis-to-be-reproducible">
<h1>This enables the analysis to be reproducible<a class="headerlink" href="#this-enables-the-analysis-to-be-reproducible" title="Permalink to this headline">¶</a></h1>
<p>set.seed(123)</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="put-3-4-of-the-data-into-the-training-set">
<h1>Put 3/4 of the data into the training set<a class="headerlink" href="#put-3-4-of-the-data-into-the-training-set" title="Permalink to this headline">¶</a></h1>
<p>data_split &lt;- initial_split(housing_df,
prop = 3/4,
strata = median_house_value,
breaks = 4)</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="create-dataframes-for-the-two-sets">
<h1>Create dataframes for the two sets:<a class="headerlink" href="#create-dataframes-for-the-two-sets" title="Permalink to this headline">¶</a></h1>
<p>train_data &lt;- training(data_split)
test_data &lt;- testing(data_split)</p>
<div class="section" id="data-exploration">
<h2>Data exploration<a class="headerlink" href="#data-exploration" title="Permalink to this headline">¶</a></h2>
<p>The point of data exploration is to gain insights that will help you select important variables for your model and to get ideas for feature engineering in the data preparation phase. Ususally, data exploration is an iterative process: once you get a prototype model up and running, you can analyze its output to gain more insights and come back to this exploration step. It is important to note that we perform data exploration only with our training data.</p>
<div class="section" id="create-data-copy">
<h3>Create data copy<a class="headerlink" href="#create-data-copy" title="Permalink to this headline">¶</a></h3>
<p>We first make a copy of the training data since we don’t want to alter our data during data exploration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore &lt;- train_data</span>
</pre></div>
</div>
</div>
</div>
<p>Next, we take a closer look at the relationships between our variables. In particular, we are interested in the relationships between our <em>dependent</em> variable <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code> and all other variables. The goal is to identify possible <em>predictor variables</em> which we could use in our models to predict the <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>.</p>
</div>
<div class="section" id="geographical-overview">
<h3>Geographical overview<a class="headerlink" href="#geographical-overview" title="Permalink to this headline">¶</a></h3>
<p>Since our data includes information about <code class="docutils literal notranslate"><span class="pre">longitude</span></code> and <code class="docutils literal notranslate"><span class="pre">latitude</span></code>, we start our data exploration with the creation of a geographical scatterplot of the data to get some first insights:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  ggplot(aes(x = longitude, y = latitude)) +</span>
<span class="c1">#  geom_point(color = &quot;cornflowerblue&quot;)</span>
</pre></div>
</div>
</div>
</div>
<p>A better visualization that highlights high-density areas (with parameter <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.1</span></code> ):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  ggplot(aes(x = longitude, y = latitude)) +</span>
<span class="c1">#  geom_point(color = &quot;cornflowerblue&quot;, alpha = 0.1) </span>
  
</pre></div>
</div>
</div>
</div>
<p>Overview about California housing prices:</p>
<ul class="simple">
<li><p>red is expensive,</p></li>
<li><p>purple is cheap and</p></li>
<li><p>larger circles indicate areas with a larger population.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  ggplot(aes(x = longitude, y = latitude)) +</span>
<span class="c1">#  geom_point(aes(size = population, color = median_house_value), </span>
<span class="c1">#             alpha = 0.4) +</span>
<span class="c1">#  scale_colour_gradientn(colours=rev(rainbow(4)))</span>
</pre></div>
</div>
</div>
</div>
<p>Lastly, we add a map to our data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#library(ggmap)</span>

<span class="c1">#qmplot(x = longitude, </span>
<span class="c1">#       y = latitude, </span>
<span class="c1">#       data = data_explore, </span>
<span class="c1">#       geom = &quot;point&quot;, </span>
<span class="c1">#       color = median_house_value, </span>
<span class="c1">#       size = population,</span>
<span class="c1">#       alpha = 0.4) +</span>
<span class="c1">#  scale_colour_gradientn(colours=rev(rainbow(4))) +</span>
<span class="c1">#  scale_alpha(guide = &#39;none&#39;) # don&#39;t show legend for alpha</span>
</pre></div>
</div>
</div>
</div>
<p>This image tells you that the housing prices are very much related to the location (e.g., close to the ocean) and to the population density. Hence our <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> variable may be a useful predictor of median housing prices, although in Northern California the housing prices in coastal districts are not too high, so it is not a simple rule.</p>
</div>
<div class="section" id="boxplots">
<h3>Boxplots<a class="headerlink" href="#boxplots" title="Permalink to this headline">¶</a></h3>
<p>We can use boxplots to check, if we actually find differences in the median house value for the different levels of the <em>categorical variable</em> <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code>. Additionally, we use the package <code class="docutils literal notranslate"><span class="pre">ggsignif</span></code> to calculate the significance of the difference between two of our groups and add the annotation to the plot in a single line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#library(ggsignif)</span>

<span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  ggplot(aes(ocean_proximity, median_house_value)) +</span>
<span class="c1">#  geom_boxplot(fill=&quot;steelblue&quot;) +</span>
<span class="c1">#  xlab(&quot;Ocean proximity&quot;) +</span>
<span class="c1">#  ylab(&quot;Median house value&quot;) +</span>
<span class="c1">#  geom_signif(comparisons = list(c(&quot;&lt;1H OCEAN&quot;, &quot;INLAND&quot;)), # calculate significance</span>
<span class="c1">#               map_signif_level=TRUE) </span>
  
</pre></div>
</div>
</div>
</div>
<p>We can observe a difference in the median house value for the different levels of our categorical variable (except between “NEAR BAY” and “NEAR OCEAN”) why we should include this variable in our model. Furthermore, the difference between “&lt;1H OCEAN” and “INLAND” is  statistically significant.</p>
</div>
<div class="section" id="correlations">
<h3>Correlations<a class="headerlink" href="#correlations" title="Permalink to this headline">¶</a></h3>
<p>Now let’s analyze our numerical variables: To obtain the correlations of our numerical data, we can use the function <code class="docutils literal notranslate"><span class="pre">vis_cor</span></code> from the <code class="docutils literal notranslate"><span class="pre">visdat</span></code> package. We use Spearman’s correlation coefficient since this measure is more insensitive to outliers than Pearson’s correlation coefficient:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#library(visdat)#</span>

<span class="c1">#data_explore %&gt;% </span>
 <span class="c1"># select(where(is.numeric)) %&gt;% # only select numerical data</span>
 <span class="c1"># vis_cor(cor_method = &quot;spearman&quot;, na_action = &quot;pairwise.complete.obs&quot;)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we take a closer look at the correlation coefficients with the package <code class="docutils literal notranslate"><span class="pre">corrr</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#library(corrr)</span>

<span class="c1"># calculate all correlations</span>
<span class="c1">#cor_res &lt;- </span>
<span class="c1">#  data_explore %&gt;%</span>
<span class="c1">#  select(where(is.numeric)) %&gt;% </span>
<span class="c1">#  correlate(method = &quot;spearman&quot;, use = &quot;pairwise.complete.obs&quot;) </span>

<span class="c1"># show correlations</span>
<span class="c1">#cor_res %&gt;% </span>
<span class="c1">#  select(term, median_house_value) %&gt;% </span>
<span class="c1">#  filter(!is.na(median_house_value)) %&gt;% # focus on dependent variable </span>
<span class="c1">#  arrange(median_house_value) %&gt;% # sort values</span>
<span class="c1">#  fashion() # print tidy correlations</span>
  
</pre></div>
</div>
</div>
</div>
<p>Furthermore, the function <code class="docutils literal notranslate"><span class="pre">network_plot</span></code> outputs a nice network plot of our data in which</p>
<ul class="simple">
<li><p>variables that are more highly correlated appear closer together and are joined by stronger paths.</p></li>
<li><p>Paths are also colored by their sign (blue for positive and red for negative).</p></li>
<li><p>The proximity of the points are determined using clustering</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;%</span>
<span class="c1">#  select(where(is.numeric)) %&gt;%  </span>
<span class="c1">#  correlate() %&gt;% </span>
<span class="c1">#  network_plot(min_cor = .15)</span>
</pre></div>
</div>
</div>
</div>
<p>Summary of our findings for the correlation analysis:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">median_income</span></code> has a strong positive correlation with <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>.</p></li>
<li><p>the new <code class="docutils literal notranslate"><span class="pre">bedrooms_per_room</span></code> attribute is negatively correlated with the <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>. Apparently houses with a lower bedroom/room ratio tend to be more expensive.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rooms_per_household</span></code> is also a bit more informative than the total number of rooms (<code class="docutils literal notranslate"><span class="pre">total_rooms</span></code>) in a district. Obviously the larger the houses, the more expensive they are (positive correlation).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">population_per_household</span></code> is negatively correlated with our dependent variable.</p></li>
</ul>
<p>As a last step in our correlation analysis, we check the statistical significance of Spearman’s rank correlations. In our example, we only obtain significant p-values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#cor.test(data_explore$median_house_value, </span>
<span class="c1">#         data_explore$population_per_household, </span>
<span class="c1">#         method = &quot;spearman&quot;, </span>
<span class="c1">#         exact=FALSE)$p.value</span>

<span class="c1">#cor.test(data_explore$median_house_value, </span>
<span class="c1">#         data_explore$bedrooms_per_room, </span>
<span class="c1">#         method = &quot;spearman&quot;, </span>
<span class="c1">#         exact=FALSE)$p.value</span>

<span class="c1">#cor.test(data_explore$median_house_value, </span>
<span class="c1">#         data_explore$rooms_per_household, </span>
<span class="c1">#         method = &quot;spearman&quot;, </span>
<span class="c1">#         exact=FALSE)$p.value</span>

<span class="c1">#cor.test(data_explore$median_house_value, </span>
<span class="c1">#         data_explore$population_per_household, </span>
<span class="c1">#         method = &quot;spearman&quot;, </span>
<span class="c1">#         exact=FALSE)$p.value</span>
</pre></div>
</div>
</div>
</div>
<p>Consequently we will use this four numerical variables as well as <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> as predictors in our model.</p>
</div>
<div class="section" id="visual-inspections">
<h3>Visual inspections<a class="headerlink" href="#visual-inspections" title="Permalink to this headline">¶</a></h3>
<p>Now let’s analyze the choosen variables in more detail. The function <code class="docutils literal notranslate"><span class="pre">ggscatmat</span></code> from the package <code class="docutils literal notranslate"><span class="pre">GGally</span></code> creates a matrix with scatterplots, densities and correlations for numeric columns. In our code we choose an alpha level of 0.2 (for transparency).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  select(median_house_value, ocean_proximity, </span>
<span class="c1">#         median_income, bedrooms_per_room, rooms_per_household, </span>
<span class="c1">#         population_per_household) %&gt;% </span>
<span class="c1">#  ggscatmat(corMethod = &quot;spearman&quot;,</span>
<span class="c1">#            alpha=0.2)</span>
</pre></div>
</div>
</div>
</div>
<p>We can also add a color column for our categorical variable <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> to get even more insights about the :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  select(median_house_value, ocean_proximity, </span>
<span class="c1">#         median_income, bedrooms_per_room, rooms_per_household, </span>
<span class="c1">#         population_per_household) %&gt;% </span>
<span class="c1">#  ggscatmat(color=&quot;ocean_proximity&quot;, # add a categorical variable</span>
<span class="c1">#            corMethod = &quot;spearman&quot;,</span>
<span class="c1">#            alpha=0.2)</span>
</pre></div>
</div>
</div>
</div>
<p>We can observe that our ocean proximity variable is indeed a good predictor for our different median house values. Another promising attribute to predict the median house value is the median income, so let’s zoom in:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#data_explore %&gt;% </span>
<span class="c1">#  ggplot(aes(median_income, median_house_value)) +</span>
<span class="c1">#  geom_jitter(color = &quot;steelblue&quot;, alpha = 0.2) + </span>
<span class="c1">#  xlab(&quot;Median income&quot;) +</span>
<span class="c1">#  ylab(&quot;Median house value&quot;) +</span>
 <span class="c1"># scale_y_continuous(labels = scales::dollar)</span>
</pre></div>
</div>
</div>
</div>
<p>This plot reveals a few things. First, the correlation is indeed very strong; you can clearly see the upward trend, and the points are not too dispersed. Second, the price cap that we noticed earlier is clearly visible as a horizontal line at 500,000 dollars. But this plot reveals other less obvious straight lines: a horizontal line around 450,000 dollars, another around 350,000 dollars, perhaps one around $280,000 dollars, and a few more below that. Hence, in our data preparation phase we will remove districts with 500,000 dollars to prevent our algorithms from learning to reproduce these data quirks.</p>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="data-preparation">
<h1>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h1>
<div class="highlight-note notranslate"><div class="highlight"><pre><span></span>Data preparation:

- Handle missing values
- Fix or remove outliers  
- Feature selection
- Feature engineering
- Feature scaling
- Create a validation set
</pre></div>
</div>
<p>Next, we’ll preprocess our data before training the models. We mainly use the tidymodels packages <code class="docutils literal notranslate"><span class="pre">recipes</span></code> and <code class="docutils literal notranslate"><span class="pre">workflows</span></code> for this steps. <code class="docutils literal notranslate"><span class="pre">Recipes</span></code> are built as a series of optional data preparation steps, such as:</p>
<ul class="simple">
<li><p><em>Data cleaning</em>: Fix or remove outliers, fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns).</p></li>
<li><p><em>Feature selection</em>: Drop the attributes that provide no useful information for the task.</p></li>
<li><p><em>Feature engineering</em>: Discretize continuous features, decompose features (e.g., the weekday from a date variable, etc.), add promising transformations of features (e.g., log(x), sqrt(x), x2 , etc.) or aggregate features into promising new features (like we already did).</p></li>
<li><p><em>Feature scaling</em>: Standardize or normalize features.</p></li>
</ul>
<p>We will want to use our recipe across several steps as we train and test our models. To simplify this process, we can use a <em>model workflow</em>, which pairs a model and recipe together.</p>
<div class="section" id="id1">
<h2>Data preparation<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Before we create our <code class="docutils literal notranslate"><span class="pre">recipes</span></code>, we first select the variables which we will use in the model. We also remove specific cases with a price in median house value equal to or greater as 500000 dollars. Note that we keep <code class="docutils literal notranslate"><span class="pre">longitude</span></code> and <code class="docutils literal notranslate"><span class="pre">latitude</span></code> to be able to map the data in a later stage but we will not use the variables in our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#housing_df_new &lt;-</span>
<span class="c1">#  housing_df %&gt;% </span>
<span class="c1">#  filter(median_house_value &lt; 500000) %&gt;% # only use houses with a value below 500000</span>
<span class="c1">#  select( # select our predictors</span>
<span class="c1">#    longitude, latitude, </span>
<span class="c1">#    median_house_value, </span>
<span class="c1">#    median_income, </span>
<span class="c1">#    ocean_proximity, </span>
<span class="c1">#    bedrooms_per_room, </span>
<span class="c1">#    rooms_per_household, </span>
 <span class="c1">#   population_per_household</span>
 <span class="c1">#        )</span>

<span class="c1">#glimpse(housing_df_new)</span>
</pre></div>
</div>
</div>
</div>
<p>Furthermore, we need to make a new data split since we updated the original data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#set.seed(123)</span>

<span class="c1">#data_split &lt;- initial_split(housing_df_new, # updated data</span>
<span class="c1">#                           prop = 3/4, </span>
<span class="c1">#                           strata = median_house_value, </span>
<span class="c1">#                           breaks = 4)</span>

<span class="c1">#train_data &lt;- training(data_split) </span>
<span class="c1">#test_data &lt;- testing(data_split)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-prepropecessing-recipe">
<h2>Data prepropecessing recipe<a class="headerlink" href="#data-prepropecessing-recipe" title="Permalink to this headline">¶</a></h2>
<p>The type of data preprocessing is dependent on the data and the type of model being fit. The excellent book “Tidy Modeling with R” provides an <a class="reference external" href="https://www.tmwr.org/pre-proc-table.html">appendix with recommendations for baseline levels of preprocessing</a> that are needed for various model functions (&#64;Kuhn2021)</p>
<p>Let’s create a base <code class="docutils literal notranslate"><span class="pre">recipe</span></code> for all of our regression models (for one of the models, we need to add a new recipe step at a later stage). Note that the sequence of steps matter:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">recipe()</span></code> function has two arguments:</p></li>
<li><p><em>A formula</em>. Any variable on the left-hand side of the tilde (<code class="docutils literal notranslate"><span class="pre">~</span></code>) is considered the model outcome (here, <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code>). On the right-hand side of the tilde are the predictors. Variables may be listed by name (separated by a <code class="docutils literal notranslate"><span class="pre">+</span></code>), or you can use the dot (<code class="docutils literal notranslate"><span class="pre">.</span></code>) to indicate all other variables as predictors.</p></li>
<li><p><em>The data</em>. A recipe is associated with the data set used to create the model. This will typically be the training set, so <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">=</span> <span class="pre">train_data</span></code> here.</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">update_role()</span></code>: This step of adding roles to a recipe is optional; the purpose of using it here is that those two variables can be retained in the data but not included in the model. This can be convenient when, after the model is fit, we want to investigate some poorly predicted value. These ID columns will be available and can be used to try to understand what went wrong.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_naomit()</span></code> removes observations (rows of data) if they contain NA or NaN values. We use <code class="docutils literal notranslate"><span class="pre">skip</span> <span class="pre">=</span> <span class="pre">TRUE</span></code> because we don’t want to perform this part to new data so that the number of samples in the assessment set is the same as the number of predicted values (even if they are NA).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_novel()</span></code> converts all nominal variables to factors and takes care of other issues related to categorical variables.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_log()</span></code> will log transform data (since some of our numerical variables are right-skewed). Note that this step can not be performed on negative numbers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_normalize()</span></code> normalizes (center and scales) the numeric variables to have a standard deviation of one and a mean of zero. (i.e., z-standardization).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_dummy()</span></code> converts our factor column <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> into numeric binary (0 and 1) variables.</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">step_zv()</span></code>: removes any numeric variables that have zero variance.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_corr()</span></code>: will remove predictor variables that have large correlations with other predictor variables.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#housing_rec &lt;-</span>
<span class="c1">#  recipe(median_house_value ~ .,</span>
<span class="c1">#         data = train_data) %&gt;%</span>
<span class="c1">#  update_role(longitude, latitude, </span>
<span class="c1">#              new_role = &quot;ID&quot;) %&gt;% </span>
<span class="c1">#  step_log(</span>
<span class="c1">#    median_house_value, median_income,</span>
<span class="c1">#    bedrooms_per_room, rooms_per_household, </span>
<span class="c1">#    population_per_household</span>
<span class="c1">#    ) %&gt;% </span>
<span class="c1">#  step_naomit(everything(), skip = TRUE) %&gt;% </span>
<span class="c1">#  step_novel(all_nominal(), -all_outcomes()) %&gt;%</span>
<span class="c1">#  step_normalize(all_numeric(), -all_outcomes(), </span>
<span class="c1">#                 -longitude, -latitude) %&gt;% </span>
<span class="c1">#  step_dummy(all_nominal()) %&gt;%</span>
<span class="c1">#  step_zv(all_numeric(), -all_outcomes()) %&gt;%</span>
<span class="c1">#  step_corr(all_predictors(), threshold = 0.7, method = &quot;spearman&quot;) </span>
</pre></div>
</div>
</div>
</div>
<p>To view the current set of variables and roles, use the <code class="docutils literal notranslate"><span class="pre">summary()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#summary(housing_rec)</span>
</pre></div>
</div>
</div>
</div>
<p>If we would like to check if all of our preprocessing steps from above actually worked, we can  proceed as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#prepped_data &lt;- </span>
<span class="c1">#  housing_rec %&gt;% # use the recipe object</span>
<span class="c1">#  prep() %&gt;% # perform the recipe on training data</span>
<span class="c1">#  juice() # extract only the preprocessed dataframe </span>
</pre></div>
</div>
</div>
</div>
<p>Take a look at the data structure:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#glimpse(prepped_data)</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#prepped_data %&gt;% </span>
<span class="c1">#  select(median_house_value, </span>
<span class="c1">#         median_income, </span>
<span class="c1">#         rooms_per_household, </span>
<span class="c1">#         population_per_household) %&gt;% </span>
<span class="c1">#  ggscatmat(corMethod = &quot;spearman&quot;,</span>
<span class="c1">#            alpha=0.2)</span>
</pre></div>
</div>
</div>
</div>
<p>You should notice that:</p>
<ul class="simple">
<li><p>the variables <code class="docutils literal notranslate"><span class="pre">longitude</span></code> and <code class="docutils literal notranslate"><span class="pre">latitude</span></code> did not change.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median_income</span></code>, <code class="docutils literal notranslate"><span class="pre">rooms_per_household</span></code> and <code class="docutils literal notranslate"><span class="pre">population_per_household</span></code> are now z-standardized and the distributions are a bit less right skewed (due to our log transformation)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> was replaced by dummy variables.</p></li>
</ul>
</div>
<div class="section" id="validation-set">
<h2>Validation set<a class="headerlink" href="#validation-set" title="Permalink to this headline">¶</a></h2>
<p>Remember that we already partitioned our data set into a <em>training set</em> and <em>test set</em>. This lets us judge whether a given model will generalize well to new data. However, using only two partitions may be insufficient when doing many rounds of hyperparameter tuning (which we don’t perform in this tutorial but it is always recommended to use a validation set).</p>
<p>Therefore, it is usually a good idea to create a so called <code class="docutils literal notranslate"><span class="pre">validation</span> <span class="pre">set</span></code>. Watch this short <a class="reference external" href="https://developers.google.com/machine-learning/crash-course/validation/video-lecture">video from Google’s Machine Learning crash course</a> to learn more about the value of a validation set.</p>
<p>We use k-fold crossvalidation to build a set of 5 validation folds with the function <code class="docutils literal notranslate"><span class="pre">vfold_cv</span></code>. We also use stratified sampling:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#set.seed(100)</span>

<span class="c1">#cv_folds &lt;-</span>
<span class="c1"># vfold_cv(train_data, </span>
<span class="c1">#          v = 5, # number of folds</span>
<span class="c1">#          strata = median_house_value,</span>
<span class="c1">#          breaks = 4) </span>
</pre></div>
</div>
</div>
</div>
<p>We will come back to the <em>validation set</em> after we specified our models.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="model-building">
<h1>Model building<a class="headerlink" href="#model-building" title="Permalink to this headline">¶</a></h1>
<div class="section" id="specify-models">
<h2>Specify models<a class="headerlink" href="#specify-models" title="Permalink to this headline">¶</a></h2>
<p>The process of specifying our models is always as follows:</p>
<ol class="simple">
<li><p>Pick a <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">type</span></code></p></li>
<li><p>set the <code class="docutils literal notranslate"><span class="pre">engine</span></code></p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">mode</span></code>: regression or classification</p></li>
</ol>
<p>You can choose the <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">engine</span></code> from this <a class="reference external" href="https://www.tidymodels.org/find/parsnip/">list</a>.</p>
<div class="section" id="lasso-regression">
<h3>Lasso regression<a class="headerlink" href="#lasso-regression" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#lasso_spec &lt;- # your model specification</span>
<span class="c1">#  linear_reg(penalty = 0.1, mixture = 1) %&gt;%  # model type and some options</span>
<span class="c1">#  set_engine(engine = &quot;glmnet&quot;) %&gt;%  # model engine</span>
<span class="c1">#  set_mode(&quot;regression&quot;) # model mode</span>

<span class="c1"># Show your model specification</span>
<span class="c1">#lasso_spec</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">penalty</span></code>: The total amount of regularization in the model. Higher values imply a higher penalty. If you choose a penalty of 0 you fit a standard linear regression model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mixture</span></code>: The mixture amounts of different types of regularization. A number between zero and one (inclusive) that is the proportion of L1 regularization (i.e. lasso) in the model. When mixture = 1, it is a pure lasso model while mixture = 0 indicates that ridge regression is being used (this works only for engines “glmnet” and “spark”).</p></li>
</ul>
<p>Note that for the lasso regression to work properly it is very important to always add a data normalization step.</p>
</div>
<div class="section" id="natural-spline">
<h3>Natural spline<a class="headerlink" href="#natural-spline" title="Permalink to this headline">¶</a></h3>
<p>To use this model correctly, we also need to add a data normalization step as well as a step to declare the degree of freedom in our model. We will include the degrees of freedom at a later step (when we create the workflows).</p>
</div>
<div class="section" id="random-forest">
<h3>Random forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="boosted-tree-xgboost">
<h3>Boosted tree (XGBoost)<a class="headerlink" href="#boosted-tree-xgboost" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="k-nearest-neighbor">
<h3>K-nearest neighbor<a class="headerlink" href="#k-nearest-neighbor" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="create-workflows">
<h2>Create workflows<a class="headerlink" href="#create-workflows" title="Permalink to this headline">¶</a></h2>
<p>To combine the data preparation recipe with the model building, we use the package <a class="reference external" href="https://workflows.tidymodels.org">workflows</a>. A workflow is an object that can bundle together your pre-processing recipe, modeling, and even post-processing requests (like calculating the RMSE).</p>
<div class="section" id="lasso">
<h3>Lasso<a class="headerlink" href="#lasso" title="Permalink to this headline">¶</a></h3>
<p>Bundle recipe and model with <code class="docutils literal notranslate"><span class="pre">workflows</span></code>:</p>
</div>
<div class="section" id="id2">
<h3>Natural spline<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>We need to declare the degrees of freedom -with <code class="docutils literal notranslate"><span class="pre">step_ns()</span></code>- for our natural spline. In our example, we just add the new step to our <code class="docutils literal notranslate"><span class="pre">housing_rec</span></code> recipe and create a new recipe which we will only use for ourse natural spline.</p>
<p>The higher the degree of freedom, the more complex the resulting model.</p>
<p>Now we bundle the recipe and our model:</p>
</div>
<div class="section" id="id3">
<h3>Random forest<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Bundle recipe and model:</p>
</div>
<div class="section" id="xgboost">
<h3>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">¶</a></h3>
<p>Bundle recipe and model:</p>
</div>
<div class="section" id="id4">
<h3>K-nearest neighbor<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Bundle recipe and model:</p>
</div>
</div>
<div class="section" id="evaluate-models">
<h2>Evaluate models<a class="headerlink" href="#evaluate-models" title="Permalink to this headline">¶</a></h2>
<p>Now we can use our validation set (<code class="docutils literal notranslate"><span class="pre">cv_folds</span></code>) to estimate the performance of our models using the <code class="docutils literal notranslate"><span class="pre">fit_resamples()</span></code> function to fit the models on each of the folds and store the results.</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">fit_resamples()</span></code> will fit our model to each resample and evaluate on the heldout set from each resample. The function is usually only used for computing performance metrics across some set of resamples to evaluate our models (like RMSE) - the models are not even stored. However, in our example we save the predictions in order to visualize the model fit and residuals with <code class="docutils literal notranslate"><span class="pre">control_resamples(save_pred</span> <span class="pre">=</span> <span class="pre">TRUE)</span></code>.</p>
<p>Finally, we collect the performance metrics with <code class="docutils literal notranslate"><span class="pre">collect_metrics()</span></code> and pick the model that does best on the validation set.</p>
<div class="section" id="id5">
<h3>Lasso regression<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>Show average performance over all folds:</p>
<p>Show performance for every single fold:</p>
<p>To assess the model predictions, we plot the predictions on the y-axis and the real median house value at the x-axis. Note that the red line is not our model. If our model would have made no mistakes at all, all points would lie on the red diagonal line (where the prediction equals the real value).</p>
<p>Let`s look at the 10 districts where our model produced the greatest residuals:</p>
<p>Show the observations in the training data.</p>
<p>In this tutorial, we don’t further investigate the reasons for the wrong predictions. In reality, we would check wether some of the districts are outliers in comparision to the rest of our data and we would need to decide if we should drop some of the cases from the data (if there are good reasons to do so).</p>
</div>
<div class="section" id="id6">
<h3>Natural spline<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>We don’t repeat all of the steps shown in lasso regression and just focus on the performance metrics.</p>
</div>
<div class="section" id="id7">
<h3>Random forest<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>We don’t repeat all of the steps shown in lasso regression and just focus on the performance metrics.</p>
</div>
<div class="section" id="id8">
<h3>XGBoost<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>We don’t repeat all of the steps shown in lasso regression and just focus on the performance metrics.</p>
</div>
<div class="section" id="id9">
<h3>K-nearest neighbor<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>We don’t repeat all of the steps shown in lasso regression and just focus on the performance metrics.</p>
</div>
<div class="section" id="compare-models">
<h3>Compare models<a class="headerlink" href="#compare-models" title="Permalink to this headline">¶</a></h3>
<p>Extract the RMSE from our models to compare them:</p>
<p>Note that the model results are quite similar.</p>
<p>Now it’s time to fit the best model (in our case the XGBoost model) one last time to the full <em>training set</em> and evaluate the resulting final model on the <em>test set</em>.</p>
</div>
</div>
<div class="section" id="last-fit-and-evaluation-on-test-set">
<h2>Last fit and evaluation on test set<a class="headerlink" href="#last-fit-and-evaluation-on-test-set" title="Permalink to this headline">¶</a></h2>
<p>Tidymodels provides the function <a class="reference external" href="https://tune.tidymodels.org/reference/last_fit.html"><code class="docutils literal notranslate"><span class="pre">last_fit()</span></code></a> which fits a model to the <em>training data</em> and evaluates it on the <em>test set</em>. We just need to provide the workflow object of the best model as well as the <strong>data split</strong> object (not the training data).</p>
<p>And this is our final result. Remember that if a model fit to the training dataset also fits the test dataset well, minimal <em>overfitting</em> has taken place. This seems to be also the case in our example.</p>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="getting_started.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Setting up Your Python Environment</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="python_by_example.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">An Introductory Example</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          Durch Jan Kirenz<br/>
        
            &copy; Urheberrechte © 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>