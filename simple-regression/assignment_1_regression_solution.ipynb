{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied Statistics**<br/>\n",
    "Prof. Dr. Jan Kirenz <br/>\n",
    "Hochschule der Medien Stuttgart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Task-a)\" data-toc-modified-id=\"Task-a)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Task a)</a></span></li><li><span><a href=\"#Task-b)\" data-toc-modified-id=\"Task-b)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Task b)</a></span><ul class=\"toc-item\"><li><span><a href=\"#b1)\" data-toc-modified-id=\"b1)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>b1)</a></span></li><li><span><a href=\"#b2)\" data-toc-modified-id=\"b2)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>b2)</a></span></li><li><span><a href=\"#b3)\" data-toc-modified-id=\"b3)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>b3)</a></span></li><li><span><a href=\"#b4)\" data-toc-modified-id=\"b4)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>b4)</a></span></li><li><span><a href=\"#b5)\" data-toc-modified-id=\"b5)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>b5)</a></span></li><li><span><a href=\"#b6):\" data-toc-modified-id=\"b6):-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>b6):</a></span></li></ul></li><li><span><a href=\"#Task-c)\" data-toc-modified-id=\"Task-c)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Task c)</a></span><ul class=\"toc-item\"><li><span><a href=\"#c1):\" data-toc-modified-id=\"c1):-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>c1):</a></span></li><li><span><a href=\"#c2)\" data-toc-modified-id=\"c2)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>c2)</a></span></li><li><span><a href=\"#c3)\" data-toc-modified-id=\"c3)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>c3)</a></span></li><li><span><a href=\"#c4)\" data-toc-modified-id=\"c4)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>c4)</a></span></li><li><span><a href=\"#c5)\" data-toc-modified-id=\"c5)-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>c5)</a></span></li></ul></li><li><span><a href=\"#d)\" data-toc-modified-id=\"d)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>d)</a></span></li><li><span><a href=\"#e)\" data-toc-modified-id=\"e)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>e)</a></span><ul class=\"toc-item\"><li><span><a href=\"#e1)\" data-toc-modified-id=\"e1)-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>e1)</a></span></li><li><span><a href=\"#e2)\" data-toc-modified-id=\"e2)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>e2)</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Generalized linear regression (GLS) with simulated data\n",
    "\n",
    "(a) Create some feature vectors. Run `np.random.seed(1)` before you create the data: \n",
    "\n",
    "   - **X1** , containing 100 observations drawn from a N (0, 1) distribution. \n",
    "   - **X2** , containing 100 observations drawn from a N (0, 0.5) distribution. \n",
    "   - **X3** , containing 100 observations drawn from a N (0.5, 2) distribution. \n",
    "\n",
    "(b) Population model 1: Using the X1 and X2 features, generate a vector **Y** according to the model (in this model, we assume a perfect relationship without any deviations from the dependent and independent variables - i.e. no error): \n",
    "\n",
    "Population model 1:\n",
    "\n",
    "$$Y = 2 + 1 \\times X1 + 0.5 \\times X2$$ \n",
    "\n",
    "This is our defined \"true\" relationship between Y and the feauters X1 and X2, also called a **population model**.\n",
    "\n",
    "- b_1) What are the values of the $β$ parameters in this linear population model? \n",
    "- b_2) What is the expected value of Y if X1 and X2 are both zero? \n",
    "- b_3) What is the expected value of Y if X1 is 1 and X2 is 2? \n",
    "- b_4) Fit a generalized least squares (gls) linear model that predicts Y using X1, X2. Comment on the model obtained (Adjusted R-Squared, F-Statistic, beta-parameters, standard errors, p-values, confidence intervalls, mean squared error, BIC, AIC). \n",
    "- b_5) Use your regression model to predict Y if X1 is 1 and X2 is 2. What is the associted standard error and 95% confidence interval?\n",
    "- b_6) Explain wether you find our population model realistic (i.e. is it plausible to have a situation where you always have a perfect relationship without any deviations between a dependent and some independet variables)?   \n",
    "\n",
    "(c) Create an error vector, **err** (error), containing 100 observations drawn from a N(0, 0.25) distribution (i.e. a normal distribution with mean zero and standard deviation 0.25) and add the error to our population model in order to define population model 2 (this is our random, non reducible error in the relationship between Y and our features ... i.e. natural deviations in the relationship):  \n",
    "\n",
    "Population model 2:\n",
    "\n",
    "$$Y = 2 + 1 \\times X1 + 0.5 \\times X2 + err$$ \n",
    "\n",
    "- c_1) What are the values of the $β$ parameters in this linear population model? \n",
    "- c_2) What is the expected value of Y if X1 and X2 are both zero? \n",
    "- c_3) What is the expected value of Y if X1 is 1 and X2 is 2? \n",
    "- c_4) Fit a generalized least squares (gls) linear model that predicts Y using X1, X2. Comment on the model obtained (Adjusted R-Squared, F-Statistic, beta-parameters, standard errors, p-values, confidence intervalls, mean squared error, BIC, AIC). \n",
    "- c_5) Use your regression model to predict Y if X1 is 1 and X2 is 2. What is the associted standard error and 95% confidence interval? \n",
    "\n",
    "(d) Now fit a generalized least squares (GLS) linear model to predict Y from task c) (population model 2) using X1, X2 and X3 in the model. Comment on the results for the X3 parameter in the model. \n",
    "\n",
    "(e) Generate a vector **Y** according to the model\n",
    "\n",
    "Population model 3:\n",
    "\n",
    "$$Y = 2 + 1 \\times X1 + 0.5 \\times X2 + X2^2 + err$$\n",
    "\n",
    "- e_1) Fit a gls model that predicts Y using X1, X2. Comment on the model obtained (Adjusted R-Squared, F-Statistic, beta-parameters, standard errors, p-values, confidence intervalls, mean squared error, BIC, AIC). \n",
    "- e_2) Fit a polynomial gls regression model that predicts Y using X1, X2 and $X^2$. Comment on the model obtained and campare it to e_2 (Adjusted R-Squared, F-Statistic, beta-parameters, standard errors, p-values, confidence intervalls, mean squared error, BIC, AIC). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distributed values (using Numpy)\n",
    "np.random.seed(1)\n",
    "X1 = np.random.normal(0, 1, 100)\n",
    "X2 = np.random.normal(0, 0.5, 100)\n",
    "X3 = np.random.normal(0.5, 2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population model\n",
    "Y = 2 + 1*X1 + 0.5*X2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_0$ = 2, $b_1$ = 1, $b_2$ = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task b_2): 2.0\n"
     ]
    }
   ],
   "source": [
    "y_1 = 2 + 1*(0) + 0.5*(0)\n",
    "print('Task b_2):', y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task b_3): 4.0\n"
     ]
    }
   ],
   "source": [
    "y_2 = 2 + 1*(1) + 0.5*(2)\n",
    "print('Task b_3):', y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.535e+32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:35:28</td>     <th>  Log-Likelihood:    </th> <td>  3430.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>  -6855.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>  -6847.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.0000</td> <td> 3.15e-17</td> <td> 6.35e+16</td> <td> 0.000</td> <td>    2.000</td> <td>    2.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    1.0000</td> <td> 3.52e-17</td> <td> 2.84e+16</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.5000</td> <td> 6.69e-17</td> <td> 7.47e+15</td> <td> 0.000</td> <td>    0.500</td> <td>    0.500</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.283</td> <th>  Durbin-Watson:     </th> <td>   2.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  12.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.826</td> <th>  Prob(JB):          </th> <td> 0.00162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.598</td> <th>  Cond. No.          </th> <td>    2.19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       1.000\n",
       "Model:                            GLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.535e+32\n",
       "Date:                Sun, 06 Jan 2019   Prob (F-statistic):               0.00\n",
       "Time:                        15:35:28   Log-Likelihood:                 3430.4\n",
       "No. Observations:                 100   AIC:                            -6855.\n",
       "Df Residuals:                      97   BIC:                            -6847.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.0000   3.15e-17   6.35e+16      0.000       2.000       2.000\n",
       "X1             1.0000   3.52e-17   2.84e+16      0.000       1.000       1.000\n",
       "X2             0.5000   6.69e-17   7.47e+15      0.000       0.500       0.500\n",
       "==============================================================================\n",
       "Omnibus:                       12.283   Durbin-Watson:                   2.287\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               12.856\n",
       "Skew:                          -0.826   Prob(JB):                      0.00162\n",
       "Kurtosis:                       3.598   Cond. No.                         2.19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X1': X1,'X2': X2,'Y': Y})\n",
    "lm = smf.gls(formula='Y ~ X1 + X2', data=df).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.64811482346484e-32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.mse_resid # approx. zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation example**: \n",
    "\n",
    "We obtain a linear regression model where we can perfectly explain all variation in the dependent variable Y with the variation in the predictors X1 and X2: $R^2=1$. \n",
    "\n",
    "Notice that this result is not due to overfitting. Instead, we obtain this unusual result because we did not even include natural variation (a non reducible error) in our linear population model (Y = 2 + 1*X1 + 0.5*X2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.336576e-16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean       mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0   4.0  1.336576e-16            4.0            4.0           4.0   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0           4.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b_5\n",
    "to_predict = pd.DataFrame({'X1':[1], 'X2':[2]})\n",
    "results = lm.get_prediction(to_predict)\n",
    "results.summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictet value equals 4; CI = 4 (since we have no variation in the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b6): \n",
    "\n",
    "not realistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distributed values, with mean = 0 and sd = 0.25\n",
    "err = np.random.normal(0, 0.25, 100)\n",
    "# Population model 2\n",
    "Y = 2 + 1*X1 + 0.5*X2 + err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c1): \n",
    "\n",
    "$b_0$ = 2, $b_1$ = 1, $b_2$ = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task c_1): 2.0\n"
     ]
    }
   ],
   "source": [
    "# c_2\n",
    "c_1 = 2 + 1*(0) + 0.5*(0)\n",
    "print('Task c_1):', y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task c_2): 4.0\n"
     ]
    }
   ],
   "source": [
    "c_2 = 2 + 1*(1) + 0.5*(2)\n",
    "print('Task c_2):', y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   572.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>1.96e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:35:28</td>     <th>  Log-Likelihood:    </th> <td> -8.9903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   23.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   31.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.9986</td> <td>    0.027</td> <td>   73.273</td> <td> 0.000</td> <td>    1.945</td> <td>    2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.9750</td> <td>    0.030</td> <td>   31.974</td> <td> 0.000</td> <td>    0.914</td> <td>    1.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.4710</td> <td>    0.058</td> <td>    8.132</td> <td> 0.000</td> <td>    0.356</td> <td>    0.586</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.827</td> <th>  Durbin-Watson:     </th> <td>   2.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.661</td> <th>  Jarque-Bera (JB):  </th> <td>   0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.101</td> <th>  Prob(JB):          </th> <td>   0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.236</td> <th>  Cond. No.          </th> <td>    2.19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.922\n",
       "Model:                            GLS   Adj. R-squared:                  0.920\n",
       "Method:                 Least Squares   F-statistic:                     572.5\n",
       "Date:                Sun, 06 Jan 2019   Prob (F-statistic):           1.96e-54\n",
       "Time:                        15:35:28   Log-Likelihood:                -8.9903\n",
       "No. Observations:                 100   AIC:                             23.98\n",
       "Df Residuals:                      97   BIC:                             31.80\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.9986      0.027     73.273      0.000       1.945       2.053\n",
       "X1             0.9750      0.030     31.974      0.000       0.914       1.035\n",
       "X2             0.4710      0.058      8.132      0.000       0.356       0.586\n",
       "==============================================================================\n",
       "Omnibus:                        0.827   Durbin-Watson:                   2.044\n",
       "Prob(Omnibus):                  0.661   Jarque-Bera (JB):                0.403\n",
       "Skew:                           0.101   Prob(JB):                        0.818\n",
       "Kurtosis:                       3.236   Cond. No.                         2.19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X1': X1,'X2': X2,'Y': Y})\n",
    "lm = smf.gls(formula='Y ~ X1 + X2', data=df).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07225076534666613"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.mse_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mse is relatively small but, because we now added variation (error) to our population model, greater than zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.915652</td>\n",
       "      <td>0.115663</td>\n",
       "      <td>3.686093</td>\n",
       "      <td>4.145211</td>\n",
       "      <td>3.334875</td>\n",
       "      <td>4.496429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  3.915652  0.115663       3.686093       4.145211      3.334875   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0      4.496429  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = pd.DataFrame({'X1':[1], 'X2':[2]})\n",
    "results = lm.get_prediction(to_predict)\n",
    "results.summary_frame(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   378.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>4.79e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:35:28</td>     <th>  Log-Likelihood:    </th> <td> -8.8804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   25.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   36.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.0015</td> <td>    0.028</td> <td>   71.211</td> <td> 0.000</td> <td>    1.946</td> <td>    2.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.9742</td> <td>    0.031</td> <td>   31.770</td> <td> 0.000</td> <td>    0.913</td> <td>    1.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.4765</td> <td>    0.059</td> <td>    8.025</td> <td> 0.000</td> <td>    0.359</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>   -0.0063</td> <td>    0.014</td> <td>   -0.460</td> <td> 0.647</td> <td>   -0.034</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.584</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.747</td> <th>  Jarque-Bera (JB):  </th> <td>   0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.065</td> <th>  Prob(JB):          </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.190</td> <th>  Cond. No.          </th> <td>    4.64</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.922\n",
       "Model:                            GLS   Adj. R-squared:                  0.920\n",
       "Method:                 Least Squares   F-statistic:                     378.6\n",
       "Date:                Sun, 06 Jan 2019   Prob (F-statistic):           4.79e-53\n",
       "Time:                        15:35:28   Log-Likelihood:                -8.8804\n",
       "No. Observations:                 100   AIC:                             25.76\n",
       "Df Residuals:                      96   BIC:                             36.18\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.0015      0.028     71.211      0.000       1.946       2.057\n",
       "X1             0.9742      0.031     31.770      0.000       0.913       1.035\n",
       "X2             0.4765      0.059      8.025      0.000       0.359       0.594\n",
       "X3            -0.0063      0.014     -0.460      0.647      -0.034       0.021\n",
       "==============================================================================\n",
       "Omnibus:                        0.584   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.747   Jarque-Bera (JB):                0.221\n",
       "Skew:                           0.065   Prob(JB):                        0.896\n",
       "Kurtosis:                       3.190   Cond. No.                         4.64\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'X1': X1,'X2': X2,'X3': X3, 'Y': Y})\n",
    "# Fit Model\n",
    "lm = smf.gls(formula='Y ~ X1 + X2 + X3', data=df).fit()\n",
    "# Print summary\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07284309824141644"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.mse_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 2 + 1*X1 + 0.5*X2 + X2**2 + err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th> <td>   0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   214.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>2.68e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:35:28</td>     <th>  Log-Likelihood:    </th> <td> -60.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   126.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   134.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.2156</td> <td>    0.045</td> <td>   48.714</td> <td> 0.000</td> <td>    2.125</td> <td>    2.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>    0.9820</td> <td>    0.051</td> <td>   19.313</td> <td> 0.000</td> <td>    0.881</td> <td>    1.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.5447</td> <td>    0.097</td> <td>    5.640</td> <td> 0.000</td> <td>    0.353</td> <td>    0.736</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>25.254</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  37.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.149</td> <th>  Prob(JB):          </th> <td>5.94e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.952</td> <th>  Cond. No.          </th> <td>    2.19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.815\n",
       "Model:                            GLS   Adj. R-squared:                  0.811\n",
       "Method:                 Least Squares   F-statistic:                     214.0\n",
       "Date:                Sun, 06 Jan 2019   Prob (F-statistic):           2.68e-36\n",
       "Time:                        15:35:28   Log-Likelihood:                -60.118\n",
       "No. Observations:                 100   AIC:                             126.2\n",
       "Df Residuals:                      97   BIC:                             134.1\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.2156      0.045     48.714      0.000       2.125       2.306\n",
       "X1             0.9820      0.051     19.313      0.000       0.881       1.083\n",
       "X2             0.5447      0.097      5.640      0.000       0.353       0.736\n",
       "==============================================================================\n",
       "Omnibus:                       25.254   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.884\n",
       "Skew:                           1.149   Prob(JB):                     5.94e-09\n",
       "Kurtosis:                       4.952   Cond. No.                         2.19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X1': X1,'X2': X2,'Y': Y})\n",
    "lm = smf.gls(formula='Y ~ X1 + X2', data=df).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2008766071299527"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.mse_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   458.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 06 Jan 2019</td> <th>  Prob (F-statistic):</th> <td>9.49e-57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:35:28</td>     <th>  Log-Likelihood:    </th> <td> -8.0720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   24.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   34.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    1.9744</td> <td>    0.033</td> <td>   60.389</td> <td> 0.000</td> <td>    1.909</td> <td>    2.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>         <td>    0.9742</td> <td>    0.030</td> <td>   32.071</td> <td> 0.000</td> <td>    0.914</td> <td>    1.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>         <td>    0.4628</td> <td>    0.058</td> <td>    7.976</td> <td> 0.000</td> <td>    0.348</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(X2 ** 2)</th> <td>    1.1118</td> <td>    0.084</td> <td>   13.261</td> <td> 0.000</td> <td>    0.945</td> <td>    1.278</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.737</td> <th>  Durbin-Watson:     </th> <td>   2.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.420</td> <th>  Jarque-Bera (JB):  </th> <td>   1.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.192</td> <th>  Prob(JB):          </th> <td>   0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.367</td> <th>  Cond. No.          </th> <td>    3.35</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.935\n",
       "Model:                            GLS   Adj. R-squared:                  0.933\n",
       "Method:                 Least Squares   F-statistic:                     458.5\n",
       "Date:                Sun, 06 Jan 2019   Prob (F-statistic):           9.49e-57\n",
       "Time:                        15:35:28   Log-Likelihood:                -8.0720\n",
       "No. Observations:                 100   AIC:                             24.14\n",
       "Df Residuals:                      96   BIC:                             34.56\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.9744      0.033     60.389      0.000       1.909       2.039\n",
       "X1             0.9742      0.030     32.071      0.000       0.914       1.034\n",
       "X2             0.4628      0.058      7.976      0.000       0.348       0.578\n",
       "I(X2 ** 2)     1.1118      0.084     13.261      0.000       0.945       1.278\n",
       "==============================================================================\n",
       "Omnibus:                        1.737   Durbin-Watson:                   2.055\n",
       "Prob(Omnibus):                  0.420   Jarque-Bera (JB):                1.172\n",
       "Skew:                           0.192   Prob(JB):                        0.556\n",
       "Kurtosis:                       3.367   Cond. No.                         3.35\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'X1': X1,'X2': X2,'Y': Y})\n",
    "lm = smf.gls(formula='Y ~ X1 + X2 + I(X2**2)', data=df).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0716749282003363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.mse_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, our model in e2) outperforms model e1) since we added the term $X_2^2$ which is also present in the population model. Therefore, the regression model is able to fit the data more closely (as can be obeserved in all test statistics)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
