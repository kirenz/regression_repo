{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied Statistics**<br/>\n",
    "Prod. Dr. Jan Kirenz <br/>\n",
    "Hochschule der Medien Stuttgart\n",
    "\n",
    "Name: foo      <br/>\n",
    "Vorname: foo   <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Multiple Linear regression \n",
    "\n",
    "This question involves the use of multiple linear regression on the **Auto** data set. In particular, only use **observations 1 to 200** for your analysis. \n",
    "\n",
    "- (a) Produce a scatterplot matrix which includes all of the variables in the data set.\n",
    "- (b) Compute the matrix of correlations between the variables using the function cor(). \n",
    "- (c) Use the statsmodel ols function to perform a multiple linear regression with **mpg** as the response and all other variables except name as the predictors. Use the summary() function to print the results. Comment on the output. For instance:\n",
    "   1. Is there a relationship between the predictors and the response?\n",
    "   2. Which predictors appear to have a statistically significant relationship to the response?\n",
    "   3. What does the coefficient for the year variable suggest?\n",
    "- (d) Use some diagnostic plots (1. Residuals vs fitted plot, 2. Normal Q-Q plot, 3. Scale-location plot, 4. Residuals vs leverage plot) to describe the linear regression fit. Comment on any problems you see with the fit. Do the residual plots suggest any unusually large outliers? Does the leverage plot identify any observations with unusually high leverage?\n",
    "- (e) Use the * and : symbols to fit linear regression models (ols) with interaction effects. Do any interactions appear to be statistically significant? Try different transformations of the X variable 'horsepower', such as log(X), sqrt(x) and $X^2$ and compare the fit with the simple model without transformation. Use the \n",
    "\n",
    "   - adjusted R-squared, \n",
    "   - mean squared error of residuals (MSE), \n",
    "   - the F-Statistic, \n",
    "   - the Bayesian Information Criterion (BIC) and\n",
    "   - Akaike's Information criterion (AIC) to comment on your findings. \n",
    "   \n",
    "  Hint: given a predictor X, we can create a predictor $X^2$ using $I(X**2)$. The function I() is needed since somy symbols have a special meaning in a formula. Furthermore, you can use np.sqrt(X) and np.log(X).\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
